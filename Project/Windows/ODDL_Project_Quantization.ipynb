{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "TF Lite model with no quantization"
      ],
      "metadata": {
        "id": "n6T9b9mDD5wW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: load the model at /content/epochs_50_no_sh.h5\n",
        "import tensorflow as tf\n",
        "from keras.models import load_model\n",
        "\n",
        "model = load_model('/content/epochs_50_no_sh.h5')\n",
        "\n",
        "# Convert the model\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# save the model\n",
        "open(\"tflite_model_no_quantization.tflite\", \"wb\").write(tflite_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G7SU5UquBz_P",
        "outputId": "f0fef74f-f536-4e04-e29e-887a90a5e2b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "456768"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The same model with float 16 quantization"
      ],
      "metadata": {
        "id": "LNZezTzZD_rf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "\n",
        "# Set the optimization mode\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "\n",
        "# Set float16 is the supported type on the target platform\n",
        "converter.target_spec.supported_types = [tf.float16]\n",
        "\n",
        "# Convert and Save the model\n",
        "tflite_model = converter.convert()\n",
        "open(\"converted_model_float16.tflite\", \"wb\").write(tflite_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68mN-31hEFei",
        "outputId": "0410e6cd-e5e4-4be2-8448-4580e026b190"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "235932"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dynamic range quantization"
      ],
      "metadata": {
        "id": "7XQoydFZEaG4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "\n",
        "# Set the optimization mode\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "\n",
        "# Convert and Save the model\n",
        "tflite_model = converter.convert()\n",
        "open(\"converted_model_drq.tflite\", \"wb\").write(tflite_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dC1PSqXEVve",
        "outputId": "b6e8e406-7811-4a26-9db8-a7f861295fa8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "122848"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Integer quantization"
      ],
      "metadata": {
        "id": "Bne5K9_AEiuN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: load all the images sequentially in /content/Jack_BSN_8r_4s.zip\n",
        "import zipfile\n",
        "from PIL import Image\n",
        "import os\n",
        "path = \"/content/Jack_BSN_8r_4s.zip\"\n",
        "with zipfile.ZipFile(path, 'r') as zip_ref:\n",
        "  zip_ref.extractall('/content/')"
      ],
      "metadata": {
        "id": "y5dFdDXhE1GF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: take first 100 images as np arrays in Jack_BSN_8r_4s folder and load them into a tensorflow tensor. Make sure that the file names ending with 000.png through 099.png are being read\n",
        "\n",
        "images = []\n",
        "for i in range(100):\n",
        "  image = Image.open('/content/Jack_BSN_8r_4s/image_1_{0:03d}.png'.format(i))\n",
        "  im_arr = np.array(image)\n",
        "  im_arr32 = im_arr.astype(np.float32)\n",
        "  images.append(np.array(im_arr32))\n",
        "\n",
        "\n",
        "images = np.array(images)\n",
        "print(images.shape)\n",
        "train_images = images.reshape((100, 640, 640, 1))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pGOa851HFhDm",
        "outputId": "9c3efac2-0a0d-4cce-c0d7-226c0a530e49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(100, 640, 640)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def representative_data_gen():\n",
        "  for input_value in tf.data.Dataset.from_tensor_slices(train_images).batch(1).take(100):\n",
        "    # Model has only one input so each data point has one element.\n",
        "    yield [input_value]\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "\n",
        "# Set the optimization mode\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "\n",
        "# Pass representative dataset to the converter\n",
        "converter.representative_dataset = representative_data_gen\n",
        "\n",
        "# Restricting supported target op specification to INT8\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "\n",
        "# Set the input and output tensors to uint8\n",
        "converter.inference_input_type = tf.uint8\n",
        "converter.inference_output_type = tf.uint8\n",
        "\n",
        "# Convert and Save the model\n",
        "tflite_model = converter.convert()\n",
        "open(\"converted_model_int8.tflite\", \"wb\").write(tflite_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZhUvAoqElGT",
        "outputId": "9c044280-fee1-453e-891f-42d5c431515d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow/lite/python/convert.py:947: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "124720"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}